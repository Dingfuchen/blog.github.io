# ELK配置
***
1. 配置elasticsearch
从官网下载tar包（5.0.1），解压到服务器（已安装jdk1.8,并配置到环境变量中）。修改/elasticsearch-5.0.1/config/elasticsearch.yml中一下几个属性值（反注释的几个属性）。 
```
network.host: 127.0.0.1
#
# Set a custom port for HTTP:
#
http.port: 8089
```
&emsp;&emsp;启动elasticsearch
```
nohup ./elasticsearch&
```
2. 配置kibana
从官网下载tar包（5.0.1），解压到服务器（已安装jdk1.8,并配置到环境变量中）。修改/kibana-5.0.1-linux-x86_64/config/kibana.yml中一下几个属性值（反注释的几个属性）。
```
server.port: 8090
	
# Specifies the address to which the Kibana server will bind. IP addresses and host names are both valid values.
# The default is 'localhost', which usually means remote machines will not be able to connect.
# To allow connections from remote users, set this parameter to a non-loopback address.
server.host: "0.0.0.0"

# Enables you to specify a path to mount Kibana at if you are running behind a proxy. This only affects
# the URLs generated by Kibana, your proxy is expected to remove the basePath value before forwarding requests
# to Kibana. This setting cannot end in a slash.
#server.basePath: ""

# The maximum payload size in bytes for incoming server requests.
#server.maxPayloadBytes: 1048576

# The Kibana server's name.  This is used for display purposes.
#server.name: "your-hostname"

# The URL of the Elasticsearch instance to use for all your queries.
elasticsearch.url: "http://127.0.0.1:8089"
```
&emsp;&emsp;启动kibana  
```
nohup ./kibana&
```
3. 配置logstash
从官网下载tar包（logstash-5.0.0），解压到服务器。在/logstash-5.0.0/config修改新建logstash.conf文件。内容如下：  
```js
input {
   redis {
        #从redis里取出日志
        host => '10.240.40.122'
        data_type => 'list'
        port => "6379"
        key => 'queue:elk:redis'
        type => 'template'
        codec => plain {
                charset => "UTF-8"
        }
   }
}

filter {
  grok {
        match => {"message" => "\s*\[%{IP:client_ip}\]\s*\[%{USERNAME:username}\]\s*\[%{LOGLEVEL:log_level}\]\s*\[(?<trans_code>([\s\S]*))\]\s*\[(?<serial_no>([\s\S]*))\]\s*\[%{JAVAFILE:java_file}\:%{NUMBER:line_number}\]\s*\[%{TIMESTAMP_ISO8601:time}\]\s*(?<info>([\s\S]*))"}
}        
          
}        
        
 
output {     
  elasticsearch {
    hosts => ["127.0.0.1:8089"]
    action => "index"
    codec => rubydebug
    index => "%{type}-%{+YYYY.MM.dd}"
    template_name => "%{type}"
  } 
  stdout { codec => rubydebug } 
}   
```
&emsp;&emsp;启动logstash，以下命令为自动刷新日志。
```
bin/logstash -f /efk/logstash-5.0.0/config/logstash.conf --config.reload.automatic&
```
&emsp;&emsp;logstash中，需要配置input, filter,output。其中input表示日志文件从此处进，此处配置的是从redis的队列中获取日志文件。filter中需要配置对应的grok语法，对日志文件进行解析，grok语法使用正则表达式，只有全匹配后才能在kibana中解析日志关键字。
***
# filebeat配置
***
filebeat需要安装在日志所在的服务器中，解压安装包后，修改目录下的filebeat.yml文件，注释掉默认的elasticsearch部分，反注释logstash部分，并在hosts下配置对应的logstash IP及端口、以及需要读取的log文件位置。
```
filebeat.prospectors:

# Each - is a prospector. Most options can be set at the prospector level, so
# you can use different prospectors for various configurations.
# Below are the prospector specific configurations.

- input_type: log

  # Paths that should be crawled and fetched. Glob based paths.
  paths:
    - /ibps/applog/trans/*.log

#-------------------------- Elasticsearch output ------------------------------
#output.elasticsearch:
  # Array of hosts to connect to.
  # hosts: ["localhost:9200"]

  # Optional protocol and basic auth credentials.
  #protocol: "https"
  #username: "elastic"
  #password: "changeme"

#----------------------------- Logstash output --------------------------------
output.logstash:
  # The Logstash hosts
  hosts: ["10.240.41.212:5044"]

```
启动filebeat
```
./filebeat start&
```